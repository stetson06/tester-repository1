---
layout: post
title: Agentic AI - Building a SQL Chatbot Agent and a Discussion on When to Use AI Agents
image: "/posts/agent_cover.png"
tags: [GenAI, Agentic AI, SQL Chatbot, LangChain, Python]

---

This project covers the end-to-end construction of an AI agent whose goal is to translate natural language questions into accruate SQL queries, retrieve real insights from a database, and explain the results clearly in plain English. At the end of the discussion, it discusses factors to consider in the employment of AI Agents, which are not 100% reliable currently.

<br>

# Introduction: AI Agents

An AI agent is a system that uses an LLM to make decisions about **what actions to take and in what order**. Instead of the usual left-to-right workflow path of traditional automation models, an AI agent takes a suite of tools to which it has been provided access and makes decisions on **how and when to use these tools** to get to some pre-defined goal.

The AI agent knows what it is looking to eventually achieve and will have **full autonomy** to decide what the workflow looks like, what it uses to achieve the goal, and in what order it will tackle the requisite subtasks. It independently figures out the "how" given the "what" and the necessary tools.

In effect, Agentic AI represents a natural GenAI progression from LLMs - whereas responses from a given LLM (e.g., Google Gemini, ChatGPT, Claude Sonnet) are just words or graphics, an AI agent leverages LLMs to tackle actual real life tasks that can vastly reduce workloads in any environment with access to a chatbot interface. It is often said that with the advent of Agentic AI, we have transitioned from "words to actions" in the world of Generative AI, defined as **AI techniques that learn from existing artifacts to generate new, realistic content (images, text, audio, code) that reflects the characteristics of the training data but does not repeat it**.

As a simple, illustrative example, let's say there's a food company ("ABC Grocery") with an on-going club membership campaign that wishes to employ an AI agent for secretarial tasks for one of its managers. It gives the AI agent access to the company's website chatbot interface, a mailing list, the manager's email account with read/write functionality, and Google work calendar. 

Let's also say a user enters into the chatbot prompt window the following question: "Can I talk to someone in person today about joining?" In response to the user's request for a meeting today, the AI agent plans out a sequence of events to achieve its goal to: 1) resolve the user's question/request; 2) move the user to the best next step; and 3) confirm the outcome with user once its task is complete.

The AI agent employs the "react" framework, using **re**ason and **act**ion to first understand the issue and then plan/take the necessary steps using its given tools. It is **fully autonomous** in how it carries out its task. In this case, the AI agent would: 1) check the manager's Google calendar for an available 15-minute time slot today; 2) if there is a slot available, book and confirm an appointment via email to both parties; 3) if not, respond back to the user with something like "Today is not available for our manager - please provide a time when you could come in within the next few days"; and 4) add the user to the mailing list.

So this simple example demonstrates the potential power of AI agents, especially in relieving staffs of basic, redundant tasks. However, there are some caveats on the employment of AI agents that we will discuss at the end.

<br>

# Overview of Project - Task from ABC Grocery Store

<br>

We again use the case of a fictional local grocery store, ABC Grocery. Their leadership would now like a quick way to monitor their operational performance metrics without having to interrupt their data staff constantly. So a SQL agent embedded in their internal corporate chatbot appears to be the perfect solution for this request.

<br>

# AI Agent Design

<br>

The AI agent must be designed to perform the following upon a user's prompt:
1. Understand the user's question/request.
2. Take action, given a suite of SQL-specific tools provided, to include access to the company's live transactional database.
3. Connect to this database.
4. Use SQL tools to figure out data, write queries, check queries, and execute queries on the database.
5. Tie raw results from SQL query to the initial prompt and convert SQL output to natural language response in the chatbox window.

<br>

# Development Methodology

<br>

This RAG project will utilize the following tools to provide ABC Grocery their requested SQL AI agent:
1. **OpenAI's ChatGPT-5**
2. **LangChain's AI ecosystem platform**
3. **Python's LangChain library**

LangChain is a single ecosystem (i.e., framework) that has virtually all of the tools needed to build full-blown GenAI applications. It helps us take an LLM and connect it with data, tools, and workflows in a clean and modular way - it's known as the "glue that sticks all the pieces of an AI app together."

<br>

# Virtual Environment

<br>

For both [OpenAI](https://platform.openai.com/docs/overview) and [LangChain](https://smith.langchain.com/), we first log-in and create the necessary API keys for each to enable Python connection to them. LangSmith is LangChain's MLOps layer (for support functions like debugging and evaluation/monitoring of the AI app). These keys are then copied onto an .env (Notepad) text file (see below) that is read by Python for the necessary API connections. 

<br>
    ![env](/img/posts/agent_env_file.png)
<br>

Assuming the "gen-ai" virtual environment already resides in Anaconda Navigator (drop-down menu at the top ribbon in the dialog box after "on"), we activate this option for this GenAI project using the code lines below in the Anaconda prompt. If it is not, then please refer back to the RAG project in this Github portfolio (look for the same "Virtual Environment" section header as above) to get this VE established prior to invoking it in the prompt.

```
> cd (path working directory)
path working directory > conda activate gen-ai
```    

<br>

# Python Code

With the virtual environment established, we proceed to coding in Python. Within the Spyder IDE, we ensure our working directory is pointing toward the folder containing the model's files. The first block of code brings in the .env information and then creates the connection string for the Postgres SQL database.

```
import os
from dotenv import load_dotenv
load_dotenv()

POSTGRES_URI = (f"postgresql+psycopg2://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}"
                f"@{os.getenv('POSTGRES_HOST')}:{os.getenv('POSTGRES_PORT')}/{os.getenv('POSTGRES_DBNAME')}?sslmode=require")
```

<br>

The "os" library is needed to grab certain parts of the Postgres connection details. The "load_dotenv" module reads the API keys from our .env text file (this is much preferred to hard-coding keys into the code, which can compromise security), ensuring we can connect to OpenAI, LangChain, and the Postgres SQL database.

The next code block below creates the actual database connection:

```
import sqlalchemy as sa

# create the database engine
engine = sa.create_engine(POSTGRES_URI,
                          pool_pre_ping=True,
                          connect_args={"options": "-c statement_timeout=15000"} # 15 second timeout
                          ) 

# check the connection
with engine.connect() as conn:
    conn.exec_driver_sql("select 1")
```

<br>

The "sqlalchemy" ("SA") library allows Python and SQL databases to talk to one another. The database engine we create serves as the intermediary between Python code and the database, preventing dropped connections and enabling the sending of queries. 

"POSTGRES_URI" refers to the long connection string we created in the last section, while the "pool_pre_ping=True" parameter value ensures each connection is still live before we run. The timeout specification ensures the program will not hang forever in the event of a run issue.

We conduct a quick test connection with the code at the end by running a very small query ("select 1"), just to prove that our credentials and network access are correct. If this line runs without error, then we know the engine is successfully talking to the Postgres SQL database (which is the case for us!).

We now proceed to set up the database connection with the next code block below:

```
from langchain_community.utilities import SQLDatabase

db = SQLDatabase(engine=engine,
                 schema="grocery_db",
                 include_tables=["customer_details", "transactions"],
                 sample_rows_in_table_info=5)

print("Usable tables:", db.get_usable_table_names())
```

<br>

We first must tell LangChain which part of the database it is allowed to interact with by wrapping our SA engine inside LangChain's SQLDatabase module. We specify the engine to enable a live connection to the Postgres SQL database. The engine includes only the two tables in the database it needs, for streamlined processing! It allows LangChain to go and fetch n = 5 number of rows from each of the two tables, which get included in the schema text it sends to the LLM. 

Through all this, the model can see real column names and data types when figuring out how to write queries that will answer the user's question(s). It also gives the LLM a small snapshot of the data up front, so it can understand what each column is - e.g., in our case, what customer ID looks like, what format a date column is in, etc. We are building an AI agent, so this information is very useful to have, as the AI agent can iterate its thinking on how to best achieve the task.

The print task uses a special function to return only those tables the model can currently access - this confirms proper loading of these tables and that the LLM also has access to them.

With this done, our next step is to create our SQL AI agent! See code below to do so:

```
from langchain_openai import ChatOpenAI

sql_agent = ChatOpenAI(model="gpt-5",
                       temperature=0)
```

<br>

OpenAI is now allowing ChatGPT-5 (its latest version currently) to be used for agentic tasks, so we invoke it here. Temperature is the parameter for creativity/randomness, with 0 equating to completely consistent, discrete/non-stochastic responses.

We now need to build the SQL toolkit and tools to assist the AI agent with its queries. See code block below:

```
from langchain_community.agent_toolkits import SQLDatabaseToolkit

toolkit = SQLDatabaseToolkit(db=db, llm=sql_agent)
tools = toolkit.get_tools()
```

<br>

The "SQLDatabaseToolkit" class comes with a suite of SQL-specific tools and abilities that lets our AI agent actually talk to the database, rather than just writing SQL queries blindly. The "tools" object is programmed to extract the actual tools that the AI agent can use, such as listing tables, checking which columns exist, running queries, even checking or fixing those queries on the fly.

It is these tools that give the AI agent the ability to inspect the database's schema and execute real SQL queries that should run reliably, instead of it just guessing what a table might look like from memory. The LangChain system makes this so so easy!

All required functionality is now set up. Our next step is to provide the SQL AI agent with our **system instructions** that it should refer to each time it runs. This document is a text file covering the following topics:
1. ROLE
2. SCOPE
3. TABLE INFORMATION
4. TABLE JOIN RELATIONSHIPS
5. DATA WINDOW
6. QUERY DESIGN RULES
7. EXAMPLE QUERIES & RESPONSE FOR GUIDANCE 

The screenshot below gives a glimpse of the "Table Information" section of the document:

<br>
    ![instructions](/img/posts/agent_instructions.png)
<br>

The code block to instantiate the document's instructional contents is below:

```
with open("sql-agent-system-prompt.txt", "r", encoding="utf-8") as f:
    system_text = f.read()
```

<br>

It is very important for this instruction document (whose resulting text object is named "system_text") to specify what the AI agent can and can not do. It must be specific and give the LLM some example responses by which it can learn approaches to common tasks (this is all in keeping with generally accepted prompting best practices and commonly employed frameworks). The agent can then extrapolate that to other tasks.

With this, we are ready to bring it all together. We can now create our SQL AI agent! See the required code block below:

```
from langchain.agents import create_agent

agent = create_agent(model=sql_agent,
                     tools=tools,
                     system_prompt=system_text)
```

<br>

The system is prompted by the "system_text" text object. Given a user question/request, the AI agent should thus be able to: 1) plan what to do; 2) call the right SQL tools; 3) look at the query results; and 4) explain the results in natural language. The SQl AI agent is ready for deployment!

Let's now run a test query through the SQL AI agent and extract the response to show how it performs.

```
from langchain_core.messages import HumanMessage

user_query = "What is the average transaction value in September 2020 for male customers who have a credit score above 0.5?"

result = agent.invoke({"messages": [HumanMessage(content=user_query)]})
print(result["messages"][-1].content)
```

<br>

Human Message is LangChain's standard message format for user input. Our AI agent expects a list of structured messages. The question is embedded in the code block. Spyder took a little over a minute to respond, but respond it did!

It first produced the SQL query it used:

```
SQL query:

with txn_values as (
  select
    t.transaction_id,
    sum(t.sales_cost) as transaction_value
  from
    grocery_db.transactions t
    join grocery_db.customer_details c on c.customer_id = t.customer_id
  where
    t.transaction_date >= date '2020-09-01'
    and t.transaction_date < date '2020-10-01'
    and c.gender = 'M'
    and c.credit_score > 0.5
  group by
    t.transaction_id
)
select
  round(avg(transaction_value), 2) as avg_transaction_value
from
  txn_values;
```

<br>

Then it returned in the console the answer:

<br>
    ![response](/img/posts/agent_response_console.png)
<br>

When we run the SQL code on SQL Workbench J (see below), it returns the same answer ($88.49), confirming the AI agent's fine work!

<br>
    ![confirmation](/img/posts/agent_workbench_confirmation.png)
<br>

When we log back into LangChain, under tracing and the project's specified name, we get the output trace on LangGraph, which is part of the LangChain ecosystem designed to address critical pain points in LLM application development, enabling custom and dynamic AI agents. This trace is captured below:

<br>
    ![trace](/img/posts/agent_langgraph1.png)
    ![cost](/img/posts/agent_langgraph2.png)
<br>

We can clearly see the user question that was processed (the trace output also listed at the bottom the SQL code used), matching the user input; it also shows that the query was successful, processing about 8K tokens over about 71 seconds, at a cost of about 3 cents. Finally, it confirms the use of a (Lang)chain!

<br>

# A Dicussion on When to Use AI Agents (and When Not to Use Them)

AI agents are not infallible - in fact, they often make mistakes and are not currently anywhere near 100% reliable. Their outputs are often inaccurate and/or non-sensical. And when something goes wrong, customers just want a human to talk to in order to fix the issue.

So there are times when to employ AI agents and other times when other more reliable, estabished automation methods should be employed.

The old school, traditional automation method is generally very reliable and trustworthy. It is triggered by a certain event (e.g., submission of an online form), which leads to a function being activated that, for instance, adds the information on the form to a central database and replies with a stock email. There are not many moving parts with no ability to deviate from a set sequence of standarized steps - so it is a very reliable, predictable/observable system. Even though there is no AI involved, it can be very valuable to the organization it supports.

Automation with AI workflows is a middle ground between traditional automation and full agentic AI employment. It's really the same process as traditional automation, just with some AI added in. For example, AI could help draft a personalized reply email after reading over the user's questions; AI could also take user input and categorize the issue into one of many categories, with a tailored email reply for each or no action taken. As with traditional automation, the workflow always proceeds from left to right in a set sequence, with no deviation allowed.

AI agents, on the other hand, don't work in sequence necessarily, designing its workflow based on its reasoning of required steps for the task, given the tools it has at its disposal. It has full autonomy to proceed however it sees fit. It can work subtasks sequentially or in parallel, assuming no dependencies. Its operational design maximizes flexibility and creativity.

So given these factors, here are some guidelines for when to employ AI agents and when to eschew them:
1. Use traditional automation when reliability is non-negotiable, tight control over outputs is needed, and/or the process is well defined and limited in scope, repeating the same way each time.
2. Use AI agents when inputs are messy and varied, every path can't be pre-planned due to the unpredictability of the scenario, and/or occasional errors can be tolerated in exchange for creative solutions with the "wow" factor highly valued.
